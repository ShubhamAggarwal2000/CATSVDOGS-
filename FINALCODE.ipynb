{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"kagglecatsanddogs_3367a/PetImages/\"\n",
    "categories = [\"Dog\" , \"Cat\"]\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(datadir , category)\n",
    "    for image in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path , image) ,0 )\n",
    "        plt.imshow(img_array , cmap=\"gray\")\n",
    "        plt.show()\n",
    "        break\n",
    "    break    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 50\n",
    "new_array = cv2.resize(img_array , (img_size , img_size))\n",
    "plt.imshow(new_array , cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in categories:\n",
    "        path = os.path.join(datadir , category)\n",
    "        class_num = categories.index(category)\n",
    "        for image in os.listdir(path):\n",
    "            try:\n",
    "                \n",
    "                img_array = cv2.imread(os.path.join(path , image) ,0 )\n",
    "                new_array = cv2.resize(img_array , (img_size , img_size))\n",
    "                training_data.append([new_array , class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                \n",
    "            \n",
    "create_training_data()         \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in training_data:\n",
    "#     print (sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for features , label in training_data:\n",
    "    x_data.append(features)\n",
    "    y_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(x_data).reshape(-1 , img_size , img_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "joblib.dump([x_data , y_data] , \"training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "data= joblib.load(\"training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_x = data[0]\n",
    "x_data = load_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_y = data[1]\n",
    "y_data = load_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\shubh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation , Flatten , Conv2D , MaxPooling2D ,Dense\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_data/255\n",
    "y =y_data\n",
    "x.shape\n",
    "x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/5\n",
      "19956/19956 [==============================] - 18s 905us/sample - loss: 0.6262 - acc: 0.6421 - val_loss: 0.5606 - val_acc: 0.7144\n",
      "Epoch 2/5\n",
      "19956/19956 [==============================] - 18s 891us/sample - loss: 0.5260 - acc: 0.7391 - val_loss: 0.5241 - val_acc: 0.7533\n",
      "Epoch 3/5\n",
      "19956/19956 [==============================] - 18s 890us/sample - loss: 0.4847 - acc: 0.7693 - val_loss: 0.4679 - val_acc: 0.7812\n",
      "Epoch 4/5\n",
      "19956/19956 [==============================] - 18s 892us/sample - loss: 0.4491 - acc: 0.7886 - val_loss: 0.4599 - val_acc: 0.7884\n",
      "Epoch 5/5\n",
      "19956/19956 [==============================] - 18s 891us/sample - loss: 0.4152 - acc: 0.8097 - val_loss: 0.4528 - val_acc: 0.7924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x263e01c6588>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64 , (3,3) , input_shape = x.shape[1:]))\n",
    "          \n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) ))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss= \"binary_crossentropy\" ,\n",
    "             optimizer= \"adam\",\n",
    "             metrics= [\"accuracy\"], \n",
    "             )\n",
    "\n",
    "model.fit(x , y ,batch_size=32 , validation_split=0.2 , epochs=5 , callbacks = [tensorbrd])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"firsttrytoclassify.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"catsvsdog{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorbrd = TensorBoard(log_dir= \"logs\\{}\".format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers =  [ 1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            name = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer , layer_size , conv_layer , int(time.time()))\n",
    "            \n",
    "             \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/5\n",
      "19956/19956 [==============================] - 8s 394us/sample - loss: 0.6265 - acc: 0.6501 - val_loss: 0.5826 - val_acc: 0.7048\n",
      "Epoch 2/5\n",
      "19956/19956 [==============================] - 7s 376us/sample - loss: 0.5505 - acc: 0.7248 - val_loss: 0.5575 - val_acc: 0.7214\n",
      "Epoch 3/5\n",
      "19956/19956 [==============================] - 7s 372us/sample - loss: 0.5179 - acc: 0.7478 - val_loss: 0.5560 - val_acc: 0.7190\n",
      "Epoch 4/5\n",
      "19956/19956 [==============================] - 7s 375us/sample - loss: 0.4942 - acc: 0.7651 - val_loss: 0.5293 - val_acc: 0.7413\n",
      "Epoch 5/5\n",
      "19956/19956 [==============================] - 7s 369us/sample - loss: 0.4775 - acc: 0.7731 - val_loss: 0.5208 - val_acc: 0.7445\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/5\n",
      "19956/19956 [==============================] - 10s 491us/sample - loss: 0.6219 - acc: 0.6439 - val_loss: 0.5919 - val_acc: 0.6731\n",
      "Epoch 2/5\n",
      "19956/19956 [==============================] - 9s 470us/sample - loss: 0.5381 - acc: 0.7284 - val_loss: 0.5217 - val_acc: 0.7367\n",
      "Epoch 3/5\n",
      "19956/19956 [==============================] - 10s 480us/sample - loss: 0.4973 - acc: 0.7614 - val_loss: 0.4955 - val_acc: 0.7669\n",
      "Epoch 4/5\n",
      "19956/19956 [==============================] - 9s 475us/sample - loss: 0.4743 - acc: 0.7773 - val_loss: 0.4871 - val_acc: 0.7735\n",
      "Epoch 5/5\n",
      "19956/19956 [==============================] - 10s 481us/sample - loss: 0.4587 - acc: 0.7852 - val_loss: 0.4924 - val_acc: 0.7665\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/5\n",
      "19956/19956 [==============================] - 11s 548us/sample - loss: 0.6601 - acc: 0.5977 - val_loss: 0.6100 - val_acc: 0.6786\n",
      "Epoch 2/5\n",
      "19956/19956 [==============================] - 10s 497us/sample - loss: 0.5697 - acc: 0.7058 - val_loss: 0.5443 - val_acc: 0.7301 - acc: 0.685 - E - ETA: 3s - loss: 0.5831  - ETA - ETA: 1s - loss: 0.5734 - acc: 0. - ETA: 0s - loss: 0.5722 \n",
      "Epoch 3/5\n",
      "19956/19956 [==============================] - 10s 497us/sample - loss: 0.5157 - acc: 0.7457 - val_loss: 0.5044 - val_acc: 0.7613- acc: 0 - ETA: 6s - loss:  -  - ETA: 3s - loss: 0.5246 - acc: 0.738 - ETA: 3s - loss: 0.5 - \n",
      "Epoch 4/5\n",
      "19956/19956 [==============================] - 10s 497us/sample - loss: 0.4838 - acc: 0.7682 - val_loss: 0.4900 - val_acc: 0.7699\n",
      "Epoch 5/5\n",
      "19956/19956 [==============================] - 10s 494us/sample - loss: 0.4533 - acc: 0.7847 - val_loss: 0.4926 - val_acc: 0.7643523 - acc - ETA: 5s - loss: 0.4529 - acc: 0.7 - ETA: 5s - loss: 0.4515 - acc: 0.78 - ETA: 5s -  - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.4560 - acc: 0.7 - ETA: 2s - loss: 0.4554 - a - ETA: 1s - loss: 0.4543 - acc: 0. - ETA: 1s - l - ETA: 0s - loss: 0.4531 - acc: 0.784\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/5\n",
      "19956/19956 [==============================] - 13s 633us/sample - loss: 0.6224 - acc: 0.6473 - val_loss: 0.5678 - val_acc: 0.7212 - loss: 0.6455 - acc: 0.618 - ETA: 3s - - ETA: 2s - loss: 0.6336 - acc: 0.633 - ETA: 2s - loss: 0.6335 - acc: 0 - ETA: 1s - loss: 0.6323 - - ETA: 1s - loss: 0.6272 - acc: 0. - ETA: 0s - loss: 0.6258 - acc: - ETA: 0s - loss: 0.6238 - acc: \n",
      "Epoch 2/5\n",
      "19956/19956 [==============================] - 12s 609us/sample - loss: 0.5421 - acc: 0.7291 - val_loss: 0.5384 - val_acc: 0.73912s - l - ETA: 0s - loss: 0.5440 - acc:  - ETA: 0s - loss: 0.5430 - acc: 0\n",
      "Epoch 3/5\n",
      "19956/19956 [==============================] - 12s 609us/sample - loss: 0.5071 - acc: 0.7561 - val_loss: 0.5257 - val_acc: 0.7465s - loss: 0.5064\n",
      "Epoch 4/5\n",
      "19956/19956 [==============================] - 12s 609us/sample - loss: 0.4825 - acc: 0.7744 - val_loss: 0.5313 - val_acc: 0.7403TA: 2s - loss - ETA: 0s - loss: 0.4824\n",
      "Epoch 5/5\n",
      "19956/19956 [==============================] - 12s 608us/sample - loss: 0.4591 - acc: 0.7866 - val_loss: 0.5382 - val_acc: 0.7409- los - ETA: 5s - loss: 0.46 - ETA: 4s - loss: - ETA: 2s - loss: 0.4562 - acc: 0.789 - ETA: 2s - loss: 0.4560 - acc: 0.7 - ETA: 2s - lo - ETA: 1s - loss: 0.4568 - acc: 0.7 - ETA: 0s - loss: 0.45\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/5\n",
      "19956/19956 [==============================] - 18s 880us/sample - loss: 0.6193 - acc: 0.6528 - val_loss: 0.6105 - val_acc: 0.6675\n",
      "Epoch 2/5\n",
      "19956/19956 [==============================] - 17s 854us/sample - loss: 0.5318 - acc: 0.7371 - val_loss: 0.5390 - val_acc: 0.7371 0.5444 - acc - ETA: 11s - - ETA: 0s - loss: 0.5314 - acc: 0\n",
      "Epoch 3/5\n",
      "19956/19956 [==============================] - 17s 854us/sample - loss: 0.4928 - acc: 0.7661 - val_loss: 0.4870 - val_acc: 0.7719 loss: 0.4957 - - ETA: 3s - loss: 0.4952 - acc: 0.7 - ETA: 3s - loss: 0.49 - ETA: 2s - loss: 0.4954 - acc: - ETA:\n",
      "Epoch 4/5\n",
      "19956/19956 [==============================] - 17s 854us/sample - loss: 0.4707 - acc: 0.7782 - val_loss: 0.4798 - val_acc: 0.7794:  - ETA: 8s - loss: 0.47 - ETA: 7s - lo - ETA: 5s - loss: 0.4678 - acc: - ETA: 5s - loss: 0.4692 - acc: 0. - ETA:  - ETA: 3s - - ETA: 1s - loss: 0.4697 - - ETA: 0s - loss: 0.4715 \n",
      "Epoch 5/5\n",
      "19956/19956 [==============================] - 17s 859us/sample - loss: 0.4469 - acc: 0.7938 - val_loss: 0.4808 - val_acc: 0.7784 ETA: 1s - loss\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/5\n",
      "19956/19956 [==============================] - 19s 948us/sample - loss: 0.6324 - acc: 0.6371 - val_loss: 0.5722 - val_acc: 0.7132\n",
      "Epoch 2/5\n",
      " 5440/19956 [=======>......................] - ETA: 12s - loss: 0.5327 - acc: 0.7410"
     ]
    }
   ],
   "source": [
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32,64,128]\n",
    "conv_layers =  [ 1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            name = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer , layer_size , conv_layer , int(time.time()))\n",
    "            tensorbrd = TensorBoard(log_dir= \"logs\\{}\".format(name))\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(layer_size , (3,3) , input_shape = x.shape[1:]))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            \n",
    "            \n",
    "            for layer in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size , (3,3) ))\n",
    "                model.add(Activation(\"relu\"))\n",
    "                model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            \n",
    "            model.add(Flatten())\n",
    "            \n",
    "            for dense_l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation(\"relu\"))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "            model.compile(loss= \"binary_crossentropy\" ,\n",
    "                         optimizer= \"adam\",\n",
    "                         metrics= [\"accuracy\"], \n",
    "                         )\n",
    "\n",
    "            model.fit(x , y ,batch_size=32 , validation_split=0.2 , epochs=5 , callbacks = [tensorbrd])\n",
    "            model.save(\"{}\".format(name))\n",
    "\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
